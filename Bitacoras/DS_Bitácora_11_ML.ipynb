{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DS_Bitácora_11_ML.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PuGU_eNlbLx"
      },
      "source": [
        "# Introducción a Machine Learning\n",
        "\n",
        "## Aprendizaje Supervisado - Clasificación\n",
        "\n",
        "En este notebook comenzamos a trabajar en los problemas de **Clasificación**, una de las tareas más importantes dentro de Machine Learning (dentro, a su vez, de lo que llamamos Aprendizaje Supervisado). Clasificación en Machine Learning consiste en aprender etiquetas discretas *y* a partir de un conjunto de features *X* (que pueden ser uno, dos, o muchos más) tomando como muestra un conjunto de instancias.\n",
        "\n",
        "Vamos a comenzar introduciendo un dataset sintético de dos features y dos clases. Y trataremos de aprender a clasificarlo usando nuestro primer modelo, un Árbol de Decisión. Haremos esto utilizando la librería Scikit-Learn. Como la mayoría de las librerías que usamos hasta ahora, tiene una documentación excelente, muy detallada y con ejemplos de uso. Muchas veces, para aprender a usar alguna herramienta de Scikit-Learn basta con copiar estos ejemplos y empezar a *jugar* con ellos. También contiene introducciones teóricas a muchos de los temas que son claras y concisas. Por último, ten en cuenta lo que vimos de funciones y programación orientada a objetos, hará mucho más fácil la comprensión de esta documentación.\n",
        "\n",
        "### 1. Ejemplo demostrativo\n",
        "\n",
        "Ahora sí, empecemos con un ejemplo *de juguete*.\n",
        "\n",
        "#### 1.1 Generando nuestro dataset\n",
        "\n",
        "Vamos a generar automáticamente un grupo de 1000 instancias con features llamados *x1* y *x2* - agrupados en una única variable `X`- a los cuales les vamos a asignar una etiqueta `y`, la cual puede valer 0 y 1. Esto lo haremos utilizando una función que ya viene incorporada en Scikit-Learn, `make_blobs`. Puede consultar la información sobre los datasets que ya vienen incorporados en Scikit-Learn [aquí](https://scikit-learn.org/stable/datasets/index.html#generated-datasets)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcAv93d7lbLx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc0WqB3clbLx"
      },
      "source": [
        "La siguiente celda genera nuestro dataset sintético."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTKKrYD5lbLx"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X, y = make_blobs(n_samples=1000, centers=2,\n",
        "                  random_state=0, cluster_std=1.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNPOuwoHlbLx"
      },
      "source": [
        "Ahora vamos a graficar las diferentes instancias que generamos como puntos en el plano (x1,x2) y les asignamos un color distinto segun cual sea su etiqueta `y`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK28aDBalbLx"
      },
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='bwr')\n",
        "plt.colorbar()\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvQ5BXrrlbLx"
      },
      "source": [
        "#### 1.2 Modelo: Árbol de decisión\n",
        "\n",
        "El primer modelo de clasificación que vamos a utilizar es un Árbol de decisión. Veremos en detalle árboles de decisión durante el siguiente encuentro. Por ahora basta que consideres que es un objeto que, dadas varias instancias con un determinados grupo de features **X** y unas determinadas etiquetas objetivo **y**, el árbol de desición aprende **automáticamente** reglas (de mayor a menor importancia) sobre cada feature de manera de poder decidir qué etiqueta le corresponde a cada instancia.\n",
        "\n",
        "Si queremos entrenar un árbol de decisión para clasificar nuestras instancias, primero debemos crear un objeto correspondiente al modelo. Este objeto será de de la clase `DecisionTreeClassifier`, la cual importamos desde la librería Scikit-Learn. Te recomendamos **fuertemente** que te vayas familiarizando con su documentación, no importa si por ahora no entiendes todo. Durante el próximo encuentro veremos más en detalle el funcionamiento de este modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2hnkp5hlbLx"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Creamos un objeto arbol\n",
        "tree = DecisionTreeClassifier(max_depth=3, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gshDHFEolbLx"
      },
      "source": [
        "Hasta ahora, lo único que hicimos fue crear el objeto, nada más.\n",
        "\n",
        "Una vez que nuestro modelo fue creado, precisamos entrenarlo sobre nuestros datos. Esto lo logramos con el método `fit(...)` que poseen **todas** las clases correspondientes a modelos de Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nWn4OM9lbLx"
      },
      "source": [
        "tree.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZrmdKIhlbLx"
      },
      "source": [
        "**¿Qué ocurrió?**\n",
        "\n",
        "El modelo ya está entrenado. Esto significa que contamos con una herramienta que, dadas ciertas características de una instancia - pares (*x1* y *x2*) - nos devuelve qué etiqueta *y* el modelo cree que le corresponde. Esto lo podemos hacer utilizando el método `predict(...)`, que también poseen **todas** las clases correspondientes a modelos de Scikit-Learn. Veamos algunos ejemplos:\n",
        "\n",
        "1. Inventando instancias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1O7fo1BlbLx"
      },
      "source": [
        "### Inventamos una instancia\n",
        "\n",
        "instancia = np.array([4,0]) # el primer valor corresponde a x1 y el segundo x2\n",
        "instancia = instancia.reshape(1,-1) # No te preocupes por ahora por el reshape. Es un requisito que quedará más claro después\n",
        "y_pred = tree.predict(instancia) # Hacemos la predicciṕn\n",
        "print(y_pred) # imprimimos en pantalla la predicción"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VsCuubIlbLx"
      },
      "source": [
        "¿Estás de acuerdo con la etiqueta asignada? Mirá en el gráfico del set de entrenamiento si estás de acuerdo con la etiqueta que nos devolvió.\n",
        "\n",
        "2. Tomando instancias del set de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxIsjyTOlbLx"
      },
      "source": [
        "### Tomamos las instancias al azar\n",
        "np.random.seed(3) # si quieres que sea al azar, cambia la semilla o comenta esta linea.\n",
        "n = 3\n",
        "idxs = np.random.randint(X.shape[0], size=3)\n",
        "instancias = X[idxs,:]\n",
        "print(instancias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI8qDeVLlbLx"
      },
      "source": [
        "### Predecimos\n",
        "y_pred = tree.predict(instancias)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI-TTLxhlbLx"
      },
      "source": [
        "### Comparamos la etiqueta real con la predicha:\n",
        "\n",
        "for i, idx in enumerate(idxs):\n",
        "    print(f'Instancia {idx}. Etiqueta real: {y[idx]}. Etiqueta predicha: {y_pred[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQkVNOp8lbLx"
      },
      "source": [
        "Ejecuta varias veces las tres celdas superiores. ¿El modelo acierta siempre? Selecciona alguna instancia cuya etiqueta no funcione y observa sus valores. ¿Por qué crees que falla? Por ejemplo, la 874:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk99hUJslbLx"
      },
      "source": [
        "k = 874\n",
        "print(X[k,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_Bzd6kdlbLx"
      },
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='bwr', alpha = 0.5)\n",
        "plt.colorbar()\n",
        "plt.scatter(X[k, 0], X[k, 1], c = 'k', s=200, cmap='bwr', marker = '*')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SU-i0mWlbLx"
      },
      "source": [
        "Volvamos sobre un aspecto del clasificador: dadas características *x1* y *x2* de una instancia, nos dice qué etiqueta *y* (0: azul, 1: rojo) le corresponde. Podemos pensar que el clasificador *pinta* el plano *x1*,*x2* de acuerdo al color que cree que corresponde. Si hay regiones azules y regiones rojas, debe existir una frontera donde el color cambie. Tratemos de visualizarla.\n",
        "\n",
        "La función que definimos en la siguiente celda nos permite explorar cómo es el dominio de decisión de nuestro arbol una vez que lo entrenamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8XusbnHlbLx"
      },
      "source": [
        "# Función que nos ayuda a graficar\n",
        "# No hace falta que comprandan este bloque de código.\n",
        "\n",
        "def visualize_classifier(model, X, y, ax=None, cmap='bwr'):\n",
        "    ax = ax or plt.gca()\n",
        "    \n",
        "    # Plot the training points\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
        "               clim=(y.min(), y.max()), zorder=3, alpha = 0.5)\n",
        "    ax.axis('tight')\n",
        "    ax.set_xlabel('x1')\n",
        "    ax.set_ylabel('x2')\n",
        "#     ax.axis('off')\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "    \n",
        "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
        "                         np.linspace(*ylim, num=200))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "    # Create a color plot with the results\n",
        "    n_classes = len(np.unique(y))\n",
        "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
        "                           levels=np.arange(n_classes + 1) - 0.5,\n",
        "                           cmap=cmap, clim=(y.min(), y.max()),\n",
        "                           zorder=1)\n",
        "\n",
        "    ax.set(xlim=xlim, ylim=ylim)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb-H0mX0lbLx"
      },
      "source": [
        "visualize_classifier(tree, X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptn80xn6lbLx"
      },
      "source": [
        "En este gráfico aquellos puntos (instancias) que queden sobre un fondo de su mismo color son aquellos que están bien clasificados por el modelo. Esto quiere decir que que si usamos el modelo para calificar su etiqueta *y* a partir de sus coordenadas *x1* y *x2*, éste nos daría la misma etiqueta original del punto. En cambio, aquellos puntos que queda sobre un fondo de otro color son puntos para los cuales el modelo nos estaría dando una etiqueta distinta a la etiqueta original de esa instancia.\n",
        "\n",
        "Nos podríamos preguntar luego: ¿cuál es el porcentaje de instancias bien clasificadas por el modelo? Para responder esto usaremos nuevamente el método `predict` sobre todo el dataset `X`. Luego con la función `accuracy_score` podemos calcular el porcentaje de aciertos que obtenemos al comparar nuestra predicción `y_pred` contra la clase original `y`. Recomendamos mirar la documentación de esta función, por ahora simplemente diremos que es una de las tantas **métricas** que utilizamos para evaluar nuestros modelos, y lo que hace es devolvernos un porcentaje de aciertos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIalkOe9lbLx"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predecimos sobre nuestro set de entrenamieto\n",
        "y_pred = tree.predict(X)\n",
        "\n",
        "# Comaparamos con las etiquetas reales\n",
        "accuracy_score(y_pred,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Zbe4GJlbLx"
      },
      "source": [
        "Esto quiere decir que el clasificador asigna la etiqueta correcta en el 90.5% de los casos.\n",
        "\n",
        "Otra forma de ver los resultados de nuestro clasificador es la **matriz de confusión**. La matriz de confusión es una tabla de doble entrada, donde un eje corresponde a la etiqueta real y otro a la etiqueta predicha. En la diagonal encontramos los aciertos, mientras que por fuera de la diagonal aquellas instancias mal clasificadas. Nuevamente, recomendamos ver la documentación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G2HgyYSlbLx"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y,y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXKXvSpJlbLx"
      },
      "source": [
        "Una forma más interesante de ver esta información es con la función `plot_confusion_matrix`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5s-u_nnlbLx"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(tree, X, y, cmap=plt.cm.Blues, values_format = '.0f')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwM8CLhHlbLx"
      },
      "source": [
        "O podemos obtener una versión **normalizada:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tAS0a_olbLx"
      },
      "source": [
        "plot_confusion_matrix(tree, X, y, cmap=plt.cm.Blues, values_format = '.2f', normalize= 'true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaMH2LrQlbLx"
      },
      "source": [
        "**Challenge - Para pensar y probar**:\n",
        "1. ¿Qué ocurre si modificas el valor de `cluster_std` en la función `make_blobs`?¿En qué casos será más fácil - o difícil - la tarea de clasificación?\n",
        "2. ¿Qué ocurre si modificas el valor de `centers` en la función `make_blobs`?¿En qué cambia la formulación del problema de clasificación?\n",
        "3. Hay algunas características de esta formulación que tal vez te llamen la atención. En el caso binario, un problema de clasificación consiste en encontrar una **frontera** entre puntos que deje a un lado los que pertenecen a una clase, y del otro lado los puntos de la otra clase. Para convencerse (¡o no!):\n",
        "    1. Elegir un problema de Clasificación Binario (al estilo Spam/No-Spam, Titanic Sobrevivió/No-Sobrevivió, etc.). Inventar - a mano - dos atributos, algunas instancias, y graficar. Luego, dibujar una frontera de decisión (siempre a mano, no tienen que programar). Un ejemplo podría ser: para clasificar vinos blancos y vinos tintos, un atributo podría ser el color y el otro podría ser el dulzor.\n",
        "    2. ¿Qué ocurre si en lugar de dos atributos tenemos tres?¿Qué forma tendrá la frontera? Y si en vez de tres atributos tenemos cuatro?¿Se podrá visualizar?\n",
        "    3. **Extra:** googlea qué es la maldición de la dimensión/dimensionalidad (curse of dimensionality).\n",
        "    \n",
        "### 2. Iris Dataset\n",
        "\n",
        "Como no podía ser de otra manera, vas a entrenar un `DecisionTreeClassifier` sobre el Iris Dataset. Te dejamos algunas consignas de guía.\n",
        "\n",
        "1. Cargar los datos. Usar la función `load_iris` de Scikit-Learn. ¿Qué tipo de dato devuelve? Pasar a un dataframe de Pandas (¡Googlear!). Prestar atención a `target` y a `target_names`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bWTIojCblbLx"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAdnx3AtlbLx"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFJ4cTNTlbLx"
      },
      "source": [
        "2. Realiza un `pairplot` de Seaborn. Elige dos variables predictoras - atributos - que te parezca que separan correctamente las clases. ¿Cuán fácil - o difícil - te parece que será la tarea de clasificación?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScM7C4ZVlbLx"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMrE8dy4lbLx"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFG63YTGlbLx"
      },
      "source": [
        "3. Separar del dataframe los atributos que elegiste (recuerda empezar por dos) y las etiquetas. Llamar `X` a los features e `y` a las etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blpr1r7klbLx"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEdTfMfplbLx"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuOkYMSHlbLx"
      },
      "source": [
        "4. Crear un DecisionTreeClassifier con `max_depth = 2` y `random_state = 42`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxjw0VLolbLy"
      },
      "source": [
        "tree = # COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS2kqHOSlbLy"
      },
      "source": [
        "5. Entrenar el DecisionTreeClassifier que creaste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zj-7QlOlbLy"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssgD9ITqlbLy"
      },
      "source": [
        "6. Explorar algunas características del modelo entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N-PhW9OlbLy"
      },
      "source": [
        "# print(tree.classes_)\n",
        "# print(tree.n_classes_)\n",
        "# print(tree.max_features_)\n",
        "# print(tree.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxK8WKmalbLy"
      },
      "source": [
        "importances = tree.feature_importances_\n",
        "columns = X.columns\n",
        "sns.barplot(columns, importances)\n",
        "plt.title('Importancia de cada Feature')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI90wIV9lbLy"
      },
      "source": [
        "7. Predecir con el modelo las etiquetas sobre todo `X`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW7JELEplbLy"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNgSBlsllbLy"
      },
      "source": [
        "8. Evaluar la performance del modelo usando `accuracy_score` y `confusion_matrix`. ¿Cuáles clases se confunden entre sí?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCNjD0_llbLy"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZSJ1mfQlbLy"
      },
      "source": [
        "# COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kluVa5folbLy"
      },
      "source": [
        "9. Visualiza las fronteras de decisión obtenidas. Te dejamos el código para hacerlo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMZfMi46lbLy"
      },
      "source": [
        "plt.figure()\n",
        "ax = sns.scatterplot(X.iloc[:,0], X.iloc[:,1], hue=y.values, palette='Set2')\n",
        "plt.legend().remove()\n",
        "\n",
        "\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
        "                      np.linspace(*ylim, num=200))\n",
        "Z = tree.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "contours = ax.contourf(xx, yy, Z, alpha=0.3, cmap = 'Set2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuIcohkFlbLy"
      },
      "source": [
        "10. ¿Qué ocurre con el desempeño a medida que aumentan `max_depth`?¿Y con las fronteras de decisión obtenidas? Vuelve a correr todas las celdas, pero inicializando el `DecisionTreeClassifier` con valores más altos de `max_depth`.\n",
        "\n",
        "11. Vuelve a entrenar, pero esta vez agregando más features a `X`. ¿Mejora o empeora el desempeño?¿Qué ocurre con las fronteras de decisión?¿Tendrá alguna relación la cantidad de features con `max_depth` óptimo?\n",
        "\n",
        "12. **Para pensar:** ¿en qué consistirá un árbol de decisión sobre un único atributo? Por ejemplo, el largo del pétalo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R37niMHlbLy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}